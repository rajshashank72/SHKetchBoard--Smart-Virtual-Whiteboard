{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dd37209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from hand_tracking import HandTracker\n",
    "from gesture_features import get_finger_states, detect_gesture\n",
    "import math\n",
    "import random\n",
    "\n",
    "color_palette = [\n",
    "    (0, 0, 255),     # Red\n",
    "    (255, 0, 0),     # Blue\n",
    "    (0, 255, 0),     # Green\n",
    "    (255, 0, 255),   # Purple\n",
    "    (0, 255, 255)    # Yellow\n",
    "]\n",
    "\n",
    "\n",
    "def distance(p1, p2):\n",
    "    return math.hypot(p2[0] - p1[0], p2[1] - p1[1])\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    \"\"\"Returns angle (in degrees) between three points.\"\"\"\n",
    "    ba = np.array([a[0]-b[0], a[1]-b[1]])\n",
    "    bc = np.array([c[0]-b[0], c[1]-b[1]])\n",
    "\n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc) + 1e-6)\n",
    "    \n",
    "    angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n",
    "    return np.degrees(angle)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "\n",
    "tracker = HandTracker()\n",
    "canvas = None\n",
    "\n",
    "draw_color = (0, 255, 255)\n",
    "thickness = 15\n",
    "prev_x, prev_y = None, None\n",
    "\n",
    "while True:\n",
    "    success, frame = cap.read()\n",
    "    # 💡 Enhance color & brightness\n",
    "    frame = cv2.convertScaleAbs(frame, alpha=1, beta=10)  # alpha=contrast, beta=brightness\n",
    "\n",
    "    # Optional: Boost saturation (convert to HSV and back)\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "    s = cv2.add(s, 40)  # Increase saturation\n",
    "    enhanced_hsv = cv2.merge([h, s, v])\n",
    "    frame = cv2.cvtColor(enhanced_hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    \n",
    "    if not success:\n",
    "        break\n",
    "      \n",
    "    if canvas is None:\n",
    "        canvas = np.zeros_like(frame)\n",
    "\n",
    "    processed_frame = tracker.process_frame(frame)\n",
    "    landmarks = tracker.results.multi_hand_landmarks\n",
    "    gesture = None\n",
    "\n",
    "    if landmarks:\n",
    "        for hand_landmarks in landmarks:\n",
    "            h, w, _ = frame.shape\n",
    "\n",
    "            # 👉 Gesture detection\n",
    "            finger_states = get_finger_states(hand_landmarks.landmark, h, w)\n",
    "            gesture = detect_gesture(finger_states)\n",
    "\n",
    "            if gesture == 'fist':\n",
    "                # ✊ Erase using black circle at index fingertip\n",
    "                tip = hand_landmarks.landmark[8]\n",
    "                tip_pos = (int(tip.x * w), int(tip.y * h))\n",
    "                cv2.circle(canvas, tip_pos, 40, (0, 0, 0), -1)\n",
    "                prev_x, prev_y = None, None\n",
    "\n",
    "            elif gesture == 'two_fingers':\n",
    "                # ✌️ Change draw color\n",
    "                draw_color = random.choice(color_palette)\n",
    "                    # At the top of your script (near imports)\n",
    "  \n",
    "\n",
    "            # 👉 Drawing logic based on index finger angle\n",
    "            mcp = hand_landmarks.landmark[6]\n",
    "            pip = hand_landmarks.landmark[7]\n",
    "            tip = hand_landmarks.landmark[8]\n",
    "\n",
    "            mcp_pos = (int(mcp.x * w), int(mcp.y * h))\n",
    "            pip_pos = (int(pip.x * w), int(pip.y * h))\n",
    "            tip_pos = (int(tip.x * w), int(tip.y * h))\n",
    "\n",
    "            angle = calculate_angle(mcp_pos, pip_pos, tip_pos)\n",
    "\n",
    "            if angle > 145 and gesture is None:\n",
    "                if prev_x is None or prev_y is None:\n",
    "                    prev_x, prev_y = tip_pos\n",
    "                cv2.line(canvas, (prev_x, prev_y), tip_pos, draw_color, thickness, cv2.LINE_AA)\n",
    "                prev_x, prev_y = tip_pos\n",
    "            else:\n",
    "                prev_x, prev_y = None, None\n",
    "\n",
    "    combined = cv2.addWeighted(processed_frame, 1, canvas, 2, 0)\n",
    "    cv2.imshow(\"Smart Virtual Whiteboard\", combined)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19a6f30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471234fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mediapipe_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
